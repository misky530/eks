package main

import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/signal"
	"strings"
	"sync"
	"syscall"
	"time"

	mqtt "github.com/eclipse/paho.mqtt.golang"
	"github.com/segmentio/kafka-go"
	"go.uber.org/zap"
)

type Config struct {
	MQTTBroker   string
	MQTTClientID string
	MQTTTopic    string
	KafkaBrokers []string
	KafkaTopic   string // æ–°å¢ï¼šç»Ÿä¸€çš„ Kafka Topic
}

// æ¶ˆæ¯ç»“æ„ï¼ˆç”¨äº JSON åºåˆ—åŒ–ï¼‰
type Message struct {
	TenantID  string    `json:"tenant_id"`
	ProjectID string    `json:"project_id"`
	Topic     string    `json:"mqtt_topic"`
	Payload   string    `json:"payload"`
	Timestamp time.Time `json:"timestamp"`
}

type Bridge struct {
	config       Config
	mqttClient   mqtt.Client
	kafkaWriter  *kafka.Writer
	logger       *zap.Logger
	messageQueue chan Message // æ–°å¢ï¼šæ¶ˆæ¯é˜Ÿåˆ—
	wg           sync.WaitGroup
	ctx          context.Context
	cancel       context.CancelFunc
}

func main() {
	// åˆå§‹åŒ–æ—¥å¿—
	logger, _ := zap.NewProduction()
	defer logger.Sync()

	// åŠ è½½é…ç½®
	config := Config{
		MQTTBroker:   getEnv("MQTT_BROKER", "tcp://hats.hcs.cn:1883"),
		MQTTClientID: getEnv("MQTT_CLIENT_ID", "mqtt-kafka-bridge"),
		MQTTTopic:    getEnv("MQTT_TOPIC", "mtic/msg/client/realtime/#"), // æ”¹ä¸ºé€šé…ç¬¦
		KafkaBrokers: strings.Split(getEnv("KAFKA_BROKERS", "iot-cluster-kafka-bootstrap.kafka:9092"), ","),
		KafkaTopic:   getEnv("KAFKA_TOPIC", "iot-messages"), // ç»Ÿä¸€ topic
	}

	logger.Info("Starting MQTT-Kafka Bridge",
		zap.String("mqtt_broker", config.MQTTBroker),
		zap.String("mqtt_topic", config.MQTTTopic),
		zap.Strings("kafka_brokers", config.KafkaBrokers),
		zap.String("kafka_topic", config.KafkaTopic),
	)

	// åˆ›å»º Bridge
	bridge := NewBridge(config, logger)

	// å¯åŠ¨
	if err := bridge.Start(); err != nil {
		logger.Fatal("Failed to start bridge", zap.Error(err))
	}

	// ç­‰å¾…é€€å‡ºä¿¡å·
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
	<-sigChan

	logger.Info("Shutting down gracefully...")
	bridge.Stop()
}

func NewBridge(config Config, logger *zap.Logger) *Bridge {
	ctx, cancel := context.WithCancel(context.Background())

	// åˆ›å»º Kafka Writer - é…ç½®ä¸ºä¸ä¸¢æ•°æ®
	kafkaWriter := &kafka.Writer{
		Addr:         kafka.TCP(config.KafkaBrokers...),
		Topic:        config.KafkaTopic, // ä½¿ç”¨ç»Ÿä¸€ topic
		Balancer:     &kafka.Hash{},     // Hash åˆ†åŒºï¼Œç›¸åŒ tenantId åˆ°åŒä¸€åˆ†åŒº
		BatchTimeout: 100 * time.Millisecond,
		WriteTimeout: 10 * time.Second,
		RequiredAcks: kafka.RequireAll, // ğŸ”¥ æ”¹ä¸ºç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
		Compression:  kafka.Snappy,
		MaxAttempts:  10, // ğŸ”¥ å¢åŠ é‡è¯•æ¬¡æ•°
		Async:        false, // ğŸ”¥ åŒæ­¥å†™å…¥
	}

	return &Bridge{
		config:       config,
		kafkaWriter:  kafkaWriter,
		logger:       logger,
		messageQueue: make(chan Message, 10000), // ğŸ”¥ æ–°å¢æ¶ˆæ¯é˜Ÿåˆ—
		ctx:          ctx,
		cancel:       cancel,
	}
}

func (b *Bridge) Start() error {
	// ğŸ”¥ å¯åŠ¨æ¶ˆæ¯å¤„ç† goroutine
	b.wg.Add(1)
	go b.messageProcessor()

	// é…ç½® MQTT å®¢æˆ·ç«¯
	opts := mqtt.NewClientOptions().
		AddBroker(b.config.MQTTBroker).
		SetClientID(b.config.MQTTClientID).
		SetKeepAlive(60 * time.Second).
		SetPingTimeout(10 * time.Second).
		SetCleanSession(false). // ğŸ”¥ æŒä¹…ä¼šè¯
		SetAutoReconnect(true).
		SetMaxReconnectInterval(10 * time.Second).
		SetConnectionLostHandler(b.onConnectionLost).
		SetOnConnectHandler(b.onConnect)

	// åˆ›å»ºå®¢æˆ·ç«¯
	b.mqttClient = mqtt.NewClient(opts)

	// è¿æ¥
	if token := b.mqttClient.Connect(); token.Wait() && token.Error() != nil {
		return fmt.Errorf("failed to connect to MQTT broker: %w", token.Error())
	}

	b.logger.Info("Connected to MQTT broker")
	return nil
}

func (b *Bridge) Stop() {
	b.logger.Info("Stopping bridge...")

	// ğŸ”¥ å–æ¶ˆ contextï¼Œåœæ­¢æ¶ˆæ¯å¤„ç†
	b.cancel()

	// æ–­å¼€ MQTT
	if b.mqttClient != nil && b.mqttClient.IsConnected() {
		b.mqttClient.Disconnect(1000) // ç­‰å¾… 1 ç§’
	}

	// ğŸ”¥ ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	b.wg.Wait()

	// å…³é—­ Kafka Writer
	if b.kafkaWriter != nil {
		b.kafkaWriter.Close()
	}

	b.logger.Info("Bridge stopped gracefully")
}

func (b *Bridge) onConnect(client mqtt.Client) {
	b.logger.Info("MQTT connected, subscribing to topic", zap.String("topic", b.config.MQTTTopic))

	// ğŸ”¥ QoS 2 è®¢é˜…ï¼ˆç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤±ï¼‰
	token := client.Subscribe(b.config.MQTTTopic, 2, b.onMessage)
	if token.Wait() && token.Error() != nil {
		b.logger.Error("Failed to subscribe", zap.Error(token.Error()))
		return
	}

	b.logger.Info("Successfully subscribed to MQTT topic")
}

func (b *Bridge) onConnectionLost(client mqtt.Client, err error) {
	b.logger.Warn("MQTT connection lost", zap.Error(err))
}

func (b *Bridge) onMessage(client mqtt.Client, msg mqtt.Message) {
	// æå– tenantId å’Œ projectId
	// Topic æ ¼å¼: mtic/msg/client/realtime/tenant123/project456
	parts := strings.Split(msg.Topic(), "/")
	if len(parts) < 6 {
		b.logger.Warn("Invalid topic format", zap.String("topic", msg.Topic()))
		return
	}

	tenantID := parts[4]
	projectID := parts[5]

	// ğŸ”¥ æ„é€ æ¶ˆæ¯å¯¹è±¡
	message := Message{
		TenantID:  tenantID,
		ProjectID: projectID,
		Topic:     msg.Topic(),
		Payload:   string(msg.Payload()),
		Timestamp: time.Now(),
	}

	// ğŸ”¥ éé˜»å¡å‘é€åˆ°é˜Ÿåˆ—
	select {
	case b.messageQueue <- message:
		// æˆåŠŸå…¥é˜Ÿ
	default:
		// é˜Ÿåˆ—æ»¡äº†ï¼Œè®°å½•ä¸¥é‡é”™è¯¯
		b.logger.Error("Message queue full, dropping message",
			zap.String("tenant_id", tenantID),
			zap.String("project_id", projectID))
	}
}

// ğŸ”¥ æ–°å¢ï¼šæ¶ˆæ¯å¤„ç†å™¨ï¼ˆæ‰¹é‡å†™å…¥ Kafkaï¼‰
func (b *Bridge) messageProcessor() {
	defer b.wg.Done()

	batch := make([]kafka.Message, 0, 100)
	ticker := time.NewTicker(1 * time.Second) // æ¯ç§’åˆ·æ–°ä¸€æ¬¡
	defer ticker.Stop()

	flush := func() {
		if len(batch) == 0 {
			return
		}

		err := b.kafkaWriter.WriteMessages(b.ctx, batch...)
		if err != nil {
			b.logger.Error("Failed to write batch to Kafka",
				zap.Error(err),
				zap.Int("batch_size", len(batch)))
		} else {
			b.logger.Info("Batch written to Kafka",
				zap.Int("count", len(batch)))
		}

		batch = batch[:0] // æ¸…ç©ºä½†ä¿ç•™å®¹é‡
	}

	for {
		select {
		case msg := <-b.messageQueue:
			// åºåˆ—åŒ–æ¶ˆæ¯ä¸º JSON
			payload, err := json.Marshal(msg)
			if err != nil {
				b.logger.Error("Failed to marshal message", zap.Error(err))
				continue
			}

			// æ·»åŠ åˆ°æ‰¹æ¬¡
			batch = append(batch, kafka.Message{
				Key:   []byte(msg.TenantID), // ä½¿ç”¨ tenantId ä½œä¸º key
				Value: payload,
				Time:  msg.Timestamp,
			})

			// æ‰¹æ¬¡æ»¡äº†ç«‹å³åˆ·æ–°
			if len(batch) >= 100 {
				flush()
			}

		case <-ticker.C:
			// å®šæ—¶åˆ·æ–°
			flush()

		case <-b.ctx.Done():
			// ä¼˜é›…å…³é—­ï¼šåˆ·æ–°å‰©ä½™æ¶ˆæ¯
			b.logger.Info("Flushing remaining messages", zap.Int("count", len(batch)))
			flush()
			return
		}
	}
}

func getEnv(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}
